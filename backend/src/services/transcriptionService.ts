import fs from 'fs/promises'
import path from 'path'
import { initGroq, hasGroqKey, API_CONFIG } from '../config/apis'
import { TranscriptionResult, TranscriptionSegment, AudioExtractionResult } from '../types'
import { AudioProcessor } from './audioProcessor'

/**
 * éŸ³é¢‘è½¬å½•æœåŠ¡ç±»
 * ä½¿ç”¨Groq Whisper Large v3 Turboè¿›è¡Œè¶…é«˜é€ŸéŸ³é¢‘è½¬å½•
 */
export class TranscriptionService {
  private static readonly RETRY_ATTEMPTS = 3
  private static readonly RETRY_DELAY = 1000 // 1ç§’

  /**
   * è½¬å½•éŸ³é¢‘æ–‡ä»¶
   */
  static async transcribeAudio(
    audioPath: string, 
    language?: string
  ): Promise<TranscriptionResult> {
    if (!hasGroqKey()) {
      throw new Error('Groq API key required for transcription but not configured')
    }

    try {
      console.log(`ğŸ¤ Starting transcription: ${audioPath}`)
      
      // éªŒè¯éŸ³é¢‘æ–‡ä»¶
      await this.validateAudioFile(audioPath)
      
      // æ‰§è¡Œè½¬å½•
      const result = await this.performTranscription(audioPath, language)
      
      console.log(`âœ… Transcription completed: ${result.text.length} characters`)
      return result

    } catch (error) {
      console.error('âŒ Transcription failed:', error)
      throw error
    }
  }

  /**
   * æ‰§è¡Œå®é™…çš„è½¬å½•æ“ä½œ
   */
  private static async performTranscription(
    audioPath: string,
    language?: string
  ): Promise<TranscriptionResult> {
    const groq = initGroq()
    
    // è¯»å–éŸ³é¢‘æ–‡ä»¶
    const audioBuffer = await fs.readFile(audioPath)
    const audioFile = new File([audioBuffer], path.basename(audioPath), {
      type: this.getMimeType(audioPath)
    })

    let lastError: Error | null = null

    // é‡è¯•æœºåˆ¶
    for (let attempt = 1; attempt <= this.RETRY_ATTEMPTS; attempt++) {
      try {
        console.log(`ğŸ”„ Transcription attempt ${attempt}/${this.RETRY_ATTEMPTS}`)
        
        const transcription = await groq.audio.transcriptions.create({
          file: audioFile,
          model: API_CONFIG.GROQ.MODEL,
          language: language || 'zh', // é»˜è®¤ä½¿ç”¨ä¸­æ–‡ï¼ŒGroqä¸æ”¯æŒautoè¯­è¨€æ£€æµ‹
          response_format: 'verbose_json', // è·å–è¯¦ç»†ä¿¡æ¯åŒ…æ‹¬æ—¶é—´æˆ³
          temperature: 0.0 // æœ€é«˜å‡†ç¡®æ€§
        })

        // å¤„ç†è½¬å½•ç»“æœ
        return this.processTranscriptionResult(transcription)

      } catch (error) {
        lastError = error as Error
        console.error(`âŒ Transcription attempt ${attempt} failed:`, error)
        
        if (attempt < this.RETRY_ATTEMPTS) {
          await this.delay(this.RETRY_DELAY * attempt)
        }
      }
    }

    throw lastError || new Error('Transcription failed after all retries')
  }

  /**
   * å¤„ç†è½¬å½•ç»“æœ
   */
  private static processTranscriptionResult(transcription: any): TranscriptionResult {
    const result: TranscriptionResult = {
      text: transcription.text || '',
      language: transcription.language || 'unknown',
      confidence: 0.95, // Groq Whisperé€šå¸¸æœ‰å¾ˆé«˜çš„å‡†ç¡®æ€§
      segments: []
    }

    // å¤„ç†åˆ†æ®µä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if (transcription.segments && Array.isArray(transcription.segments)) {
      result.segments = transcription.segments.map((segment: any) => ({
        start: segment.start || 0,
        end: segment.end || 0,
        text: segment.text || '',
        confidence: segment.avg_logprob ? Math.exp(segment.avg_logprob) : 0.9
      }))
    }

    return result
  }

  /**
   * æ‰¹é‡è½¬å½•å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
   */
  static async transcribeMultipleFiles(
    audioPaths: string[],
    language?: string
  ): Promise<TranscriptionResult> {
    const results: TranscriptionResult[] = []
    
    console.log(`ğŸµ Transcribing ${audioPaths.length} audio segments`)

    for (let i = 0; i < audioPaths.length; i++) {
      const audioPath = audioPaths[i]
      console.log(`ğŸ“ Processing segment ${i + 1}/${audioPaths.length}`)
      
      try {
        const result = await this.transcribeAudio(audioPath, language)
        results.push(result)
      } catch (error) {
        console.error(`âŒ Failed to transcribe segment ${i + 1}:`, error)
        // ç»§ç»­å¤„ç†å…¶ä»–æ®µï¼Œä½†è®°å½•é”™è¯¯
        results.push({
          text: `[Transcription failed for segment ${i + 1}]`,
          language: language || 'unknown',
          confidence: 0,
          segments: []
        })
      }
    }

    // åˆå¹¶æ‰€æœ‰è½¬å½•ç»“æœ
    return this.mergeTranscriptionResults(results)
  }

  /**
   * åˆå¹¶å¤šä¸ªè½¬å½•ç»“æœ
   */
  private static mergeTranscriptionResults(results: TranscriptionResult[]): TranscriptionResult {
    const mergedResult: TranscriptionResult = {
      text: '',
      language: results[0]?.language || 'unknown',
      confidence: 0,
      segments: []
    }

    let totalConfidence = 0
    let segmentOffset = 0

    for (const result of results) {
      // åˆå¹¶æ–‡æœ¬
      if (mergedResult.text && result.text) {
        mergedResult.text += ' '
      }
      mergedResult.text += result.text

      // ç´¯è®¡ç½®ä¿¡åº¦
      totalConfidence += result.confidence

      // åˆå¹¶åˆ†æ®µï¼ˆè°ƒæ•´æ—¶é—´åç§»ï¼‰
      if (result.segments) {
        const adjustedSegments = result.segments.map(segment => ({
          ...segment,
          start: segment.start + segmentOffset,
          end: segment.end + segmentOffset
        }))
        mergedResult.segments!.push(...adjustedSegments)
        
        // æ›´æ–°åç§»é‡ï¼ˆå‡è®¾æ¯æ®µå¤§çº¦10åˆ†é’Ÿï¼‰
        segmentOffset += 600
      }
    }

    // è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
    mergedResult.confidence = results.length > 0 ? totalConfidence / results.length : 0

    return mergedResult
  }

  /**
   * æ™ºèƒ½è½¬å½•ï¼ˆåŒ…å«éŸ³é¢‘é¢„å¤„ç†å’Œåˆ†å‰²ï¼‰
   */
  static async smartTranscribe(
    audioResult: AudioExtractionResult,
    videoId: string,
    language?: string
  ): Promise<TranscriptionResult> {
    console.log(`ğŸ§  Starting smart transcription for ${videoId}`)

    try {
      // æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œå†³å®šæ˜¯å¦éœ€è¦åˆ†å‰²
      if (audioResult.size > API_CONFIG.GROQ.MAX_FILE_SIZE) {
        console.log('ğŸ“‚ Audio file too large, splitting into segments')
        
        // ä½¿ç”¨AudioProcessoråˆ†å‰²å¤§æ–‡ä»¶
        const segmentPaths = await AudioProcessor.splitLargeAudio(audioResult.audioPath, videoId)
        
        if (segmentPaths.length === 0) {
          throw new Error('Failed to split audio file into segments')
        }
        
        console.log(`ğŸ“ Split audio into ${segmentPaths.length} segments`)
        return await this.transcribeMultipleFiles(segmentPaths, language)
      } else {
        return await this.transcribeAudio(audioResult.audioPath, language)
      }

    } catch (error) {
      console.error('âŒ Smart transcription failed:', error)
      throw error
    }
  }

  /**
   * éªŒè¯éŸ³é¢‘æ–‡ä»¶
   */
  private static async validateAudioFile(audioPath: string): Promise<void> {
    try {
      await fs.access(audioPath)
      
      const stats = await fs.stat(audioPath)
      if (stats.size === 0) {
        throw new Error('Audio file is empty')
      }
      
      if (stats.size > API_CONFIG.GROQ.MAX_FILE_SIZE) {
        throw new Error('Audio file exceeds maximum size limit')
      }

      const extension = path.extname(audioPath).toLowerCase().slice(1)
      if (!API_CONFIG.GROQ.SUPPORTED_FORMATS.includes(extension)) {
        throw new Error(`Audio format '${extension}' is not supported`)
      }

    } catch (error) {
      throw new Error(`Audio file validation failed: ${error instanceof Error ? error.message : String(error)}`)
    }
  }

  /**
   * è·å–éŸ³é¢‘æ–‡ä»¶çš„MIMEç±»å‹
   */
  private static getMimeType(audioPath: string): string {
    const extension = path.extname(audioPath).toLowerCase()
    const mimeTypes: { [key: string]: string } = {
      '.mp3': 'audio/mpeg',
      '.wav': 'audio/wav',
      '.m4a': 'audio/mp4',
      '.webm': 'audio/webm',
      '.mp4': 'video/mp4'
    }
    
    return mimeTypes[extension] || 'audio/mpeg'
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }



  /**
   * è·å–è½¬å½•ç»Ÿè®¡ä¿¡æ¯
   */
  static getTranscriptionStats(result: TranscriptionResult): {
    characterCount: number
    wordCount: number
    segmentCount: number
    averageConfidence: number
    estimatedDuration: number
  } {
    const characterCount = result.text.length
    const wordCount = result.text.split(/\s+/).filter(word => word.length > 0).length
    const segmentCount = result.segments?.length || 0
    
    let averageConfidence = result.confidence
    if (result.segments && result.segments.length > 0) {
      const totalConfidence = result.segments.reduce((sum, segment) => sum + segment.confidence, 0)
      averageConfidence = totalConfidence / result.segments.length
    }
    
    const estimatedDuration = result.segments && result.segments.length > 0
      ? Math.max(...result.segments.map(s => s.end))
      : wordCount / 150 * 60 // ä¼°ç®—ï¼š150è¯/åˆ†é’Ÿ
    
    return {
      characterCount,
      wordCount,
      segmentCount,
      averageConfidence: Math.round(averageConfidence * 1000) / 1000,
      estimatedDuration: Math.round(estimatedDuration)
    }
  }
}