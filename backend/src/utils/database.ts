import { pool } from '../config/database'
import fs from 'fs'
import path from 'path'

export class DatabaseManager {
  /**
   * è¿è¡Œæ•°æ®åº“è¿ç§»
   */
  static async runMigrations() {
    const migrationsDir = path.join(process.cwd(), '../database/migrations')
    
    try {
      // åˆ›å»ºmigrationsè¡¨æ¥è·Ÿè¸ªå·²æ‰§è¡Œçš„è¿ç§»
      await pool.query(`
        CREATE TABLE IF NOT EXISTS schema_migrations (
          id SERIAL PRIMARY KEY,
          filename VARCHAR(255) UNIQUE NOT NULL,
          executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
      `)

      // èŽ·å–æ‰€æœ‰è¿ç§»æ–‡ä»¶
      const migrationFiles = fs.readdirSync(migrationsDir)
        .filter(file => file.endsWith('.sql'))
        .sort()

      // èŽ·å–å·²æ‰§è¡Œçš„è¿ç§»
      const { rows: executedMigrations } = await pool.query(
        'SELECT filename FROM schema_migrations'
      )
      const executed = executedMigrations.map(row => row.filename)

      // æ‰§è¡Œæœªæ‰§è¡Œçš„è¿ç§»
      for (const file of migrationFiles) {
        if (!executed.includes(file)) {
          console.log(`Running migration: ${file}`)
          
          const migrationPath = path.join(migrationsDir, file)
          const migrationSql = fs.readFileSync(migrationPath, 'utf8')
          
          await pool.query(migrationSql)
          await pool.query(
            'INSERT INTO schema_migrations (filename) VALUES ($1)',
            [file]
          )
          
          console.log(`âœ… Migration ${file} completed`)
        }
      }

      console.log('ðŸš€ All migrations completed successfully')
    } catch (error) {
      console.error('âŒ Migration failed:', error)
      throw error
    }
  }

  /**
   * è¿è¡Œç§å­æ•°æ®
   */
  static async runSeeds() {
    const seedsDir = path.join(process.cwd(), '../database/seeds')
    
    try {
      // æ£€æŸ¥æ˜¯å¦å·²æœ‰ç§å­æ•°æ®
      const { rows } = await pool.query('SELECT COUNT(*) FROM users')
      if (parseInt(rows[0].count) > 0) {
        console.log('âš ï¸  Database already contains data, skipping seeds')
        return
      }

      // èŽ·å–æ‰€æœ‰ç§å­æ–‡ä»¶
      const seedFiles = fs.readdirSync(seedsDir)
        .filter(file => file.endsWith('.sql'))
        .sort()

      // æ‰§è¡Œç§å­æ–‡ä»¶
      for (const file of seedFiles) {
        console.log(`Running seed: ${file}`)
        
        const seedPath = path.join(seedsDir, file)
        const seedSql = fs.readFileSync(seedPath, 'utf8')
        
        await pool.query(seedSql)
        console.log(`âœ… Seed ${file} completed`)
      }

      console.log('ðŸŒ± All seeds completed successfully')
    } catch (error) {
      console.error('âŒ Seeding failed:', error)
      throw error
    }
  }

  /**
   * é‡ç½®æ•°æ®åº“
   */
  static async resetDatabase() {
    try {
      console.log('ðŸ”„ Resetting database...')
      
      // åˆ é™¤æ‰€æœ‰è¡¨
      await pool.query(`
        DROP SCHEMA public CASCADE;
        CREATE SCHEMA public;
        GRANT ALL ON SCHEMA public TO public;
      `)

      console.log('âœ… Database reset completed')
    } catch (error) {
      console.error('âŒ Database reset failed:', error)
      throw error
    }
  }

  /**
   * æ£€æŸ¥æ•°æ®åº“è¿žæŽ¥å’ŒåŸºæœ¬åŠŸèƒ½
   */
  static async healthCheck() {
    try {
      // åŸºæœ¬è¿žæŽ¥æµ‹è¯•
      const { rows } = await pool.query('SELECT NOW() as current_time, version() as pg_version')
      
      // æ£€æŸ¥æ ¸å¿ƒè¡¨æ˜¯å¦å­˜åœ¨
      const { rows: tables } = await pool.query(`
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
      `)

      const expectedTables = ['users', 'video_processes', 'concepts', 'knowledge_graphs', 'study_cards']
      const existingTables = tables.map(t => t.table_name)
      const missingTables = expectedTables.filter(table => !existingTables.includes(table))

      return {
        status: 'healthy',
        timestamp: rows[0].current_time,
        postgresql_version: rows[0].pg_version,
        tables_count: existingTables.length,
        missing_tables: missingTables,
        all_tables_exist: missingTables.length === 0
      }
    } catch (error) {
      return {
        status: 'unhealthy',
        error: error.message
      }
    }
  }

  /**
   * èŽ·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
   */
  static async getStats() {
    try {
      const stats = {}

      // ç”¨æˆ·ç»Ÿè®¡
      const { rows: userStats } = await pool.query(`
        SELECT 
          COUNT(*) as total_users,
          COUNT(*) FILTER (WHERE plan = 'free') as free_users,
          COUNT(*) FILTER (WHERE plan = 'basic') as basic_users,
          COUNT(*) FILTER (WHERE plan = 'pro') as pro_users,
          COUNT(*) FILTER (WHERE created_at >= CURRENT_DATE) as new_users_today
        FROM users
      `)
      stats.users = userStats[0]

      // è§†é¢‘å¤„ç†ç»Ÿè®¡
      const { rows: videoStats } = await pool.query(`
        SELECT 
          COUNT(*) as total_processes,
          COUNT(*) FILTER (WHERE status = 'completed') as completed,
          COUNT(*) FILTER (WHERE status = 'failed') as failed,
          COUNT(*) FILTER (WHERE status = 'processing') as processing,
          COUNT(*) FILTER (WHERE created_at >= CURRENT_DATE) as today_processes,
          AVG(processing_time) as avg_processing_time
        FROM video_processes
      `)
      stats.videos = videoStats[0]

      // æ¦‚å¿µç»Ÿè®¡
      const { rows: conceptStats } = await pool.query(`
        SELECT 
          COUNT(*) as total_concepts,
          COUNT(DISTINCT category) as categories,
          AVG(usage_count) as avg_usage
        FROM concepts
      `)
      stats.concepts = conceptStats[0]

      return stats
    } catch (error) {
      throw new Error(`Stats query failed: ${error.message}`)
    }
  }
}